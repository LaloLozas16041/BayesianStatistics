\section*{MOTIVACIÓN DEL ENFOQUE BAYESIANO}

La Estadística Bayesiana es fundamental en el ámbito de la Ciencia de Datos y el Aprendizaje Automático, con aplicaciones prácticas en diversas áreas como la medicina y el marketing online. Este enfoque es especialmente valioso en situaciones donde los datos se actualizan continuamente, permitiendo decisiones basadas en la acumulación de evidencia.

El enfoque Bayesiano se distingue por su interpretación de la probabilidad como un grado de creencia, lo cual se alinea con la forma en que se procesa la información en el mundo real. Las pruebas A/B son un ejemplo clásico, donde se selecciona la mejor opción entre dos posibles para maximizar un resultado deseado, ya sea en publicidad, medicina o cualquier otro campo.

Comenzaremos explorando los conceptos básicos y fundamentos teóricos, construyendo hacia una comprensión profunda de qué es la probabilidad y cómo se aplica en el enfoque Bayesiano.

---

\section{Conceptos Básicos}

\subsection{Distribución Conjunta, Marginales y Condicionales}

Vamos a suponer que tenemos dos variables aleatorias $A$ y $B$, las distribuciones marginales serían: $p(A)$, $p(B)$.

La distribución conjunta la denotaremos como $p(A, B)$. La coma es una forma abreviada de decir "y".

Y por último tenemos la distribución condicional, a la que nos referimos como $p(A|B)$ o $p(B|A)$.

La barra vertical es el símbolo que usamos para representar a una condición, condicionado a algo. Esto se lee P de A, dado B; y P de B, dado A. La distribución conjunta es la más general porque es a partir de esta distribución que podemos calcular todo lo demás.

Podemos calcular la distribución marginal si tenemos la distribución conjunta, de la siguiente manera:

$$ p(A) = \sum_{B} p(A, B) $$

$$ p(B) = \sum_{A} p(A, B) $$

---

También podemos calcular la distribución condicional usando la conjunta y la marginal:

$$
p(A|B) = \frac{p(A, B)}{p(B)} = \frac{p(A, B)}{\sum_A p(A, B)}
$$

$$
p(B|A) = \frac{p(A, B)}{p(A)} = \frac{p(A, B)}{\sum_B p(A, B)}
$$

La distribución conjunta es fundamental para calcular la condicional, como se demuestra en las ecuaciones anteriores. A partir de aquí, podemos deducir el Teorema de Bayes y entender que las distribuciones pueden calcularse una a partir de la otra.

Para variables continuas, las sumas se convierten en integrales, y usamos funciones de densidad de probabilidad:

$$
f(x, y) \quad \text{Densidad conjunta}
$$
$$
f(x) \quad \text{Densidades marginales}
$$

---