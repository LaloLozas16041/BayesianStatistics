# MOTIVACIÓN DEL ENFOQUE BAYESIANO

La Estadística Bayesiana es crucial en Estadística, Ciencia de Datos y Machine Learning. Se aplica en medicina, estimando enfermedades y en marketing digital para evaluar anuncios. Este enfoque se actualiza con datos nuevos, contrario a los métodos "online" estáticos.

Se destaca en pruebas A/B, seleccionando la opción que maximiza beneficios. Por ejemplo, Facebook optimiza qué anuncios mostrar para beneficiar al usuario y al anunciante. La Estadística Bayesiana se basa en la interpretación de la probabilidad como una medida de credibilidad.

Se abordarán los fundamentos, como la definición de probabilidad y el razonamiento dentro del marco bayesiano, preparando para métodos más avanzados de inferencia bayesiana y análisis de datos.

## Conceptos Básicos

### Distribución Conjunta, Marginales y Condicionales

Vamos a suponer que tenemos dos variables aleatorias $A$ y $B$, las distribuciones marginales serían:

- $p(A)$
- $p(B)$

La distribución conjunta la denotaremos como $p(A, B)$. La coma es una forma abreviada de decir "y".

La distribución condicional, a la que nos referimos como $p(A|B)$ o $p(B|A)$.

La barra vertical es el símbolo que usamos para representar una condición. La distribución conjunta es la más general porque es a partir de esta distribución que podemos calcular todo lo demás.

Podemos calcular la distribución marginal si tenemos la distribución conjunta, de la siguiente manera:

- $p(A) = \sum_{B} p(A, B)$
- $p(B) = \sum_{A} p(A, B)$

También podemos calcular la distribución condicional usando la conjunta y la marginal:

$$
p(A|B) = \frac{p(A, B)}{p(B)} = \frac{p(A, B)}{\sum_{A} p(A, B)}
$$

$$
p(B|A) = \frac{p(A, B)}{p(A)} = \frac{p(A, B)}{\sum_{B} p(A, B)}
$$

Como sabemos que la marginal se puede calcular a partir de la conjunta, solo necesitamos la conjunta para calcular la condicional.

Podemos calcular la distribución condicional inversa si solo tenemos la condicional y la marginal. Usando la regla de las probabilidades condicionales, podemos reorganizar los términos:

$$
p(B|A) = \frac{p(A, B)}{p(A)} = \frac{p(A|B)p(B)}{\sum_{B} p(A|B)p(B)}
$$

Esto implica que podemos calcular la distribución conjunta a partir de la condicional y la marginal, lo que nos lleva al Teorema de Bayes.

Para variables continuas, las sumas se convierten en integrales:

- Densidad conjunta: $f(x, y)$
- Densidades marginales: $f(x)$, $f(y)$

$$
f(x) = \int f(x, y) \, dy
$$

$$
f(y) = \int f(x, y) \, dx
$$

Y la distribución condicional:

$$
f(x|y) = \frac{f(x, y)}{f(y)} = \frac{f(x, y)}{\int f(x, y) \, dx}
$$

$$
f(y|x) = \frac{f(x, y)}{f(x)} = \frac{f(x, y)}{\int f(x, y) \, dy}
$$

Además, la regla de Bayes también se expresa de forma análoga:

$$
f(x|y) = \frac{f(y|x)f(x)}{\int f(y|x)f(x) \, dx}
$$

$$
f(y|x) = \frac{f(x|y)f(y)}{\int f(x|y)f(y) \, dy}
$$

Simplemente reemplazamos la suma con una integral sobre la variable aleatoria relevante.

# MÁXIMA VEROSIMILITUD: DISTRIBUCIÓN DE BERNOULLI

La estimación de máxima verosimilitud es una técnica de estadística que consiste en ajustar un modelo a los datos para encontrar los mejores parámetros que modelen los datos lo más cerca posible de la realidad. Este concepto es fundamental en el aprendizaje de modelos en Machine Learning, como los modelos de clasificación y las redes neuronales en el aprendizaje profundo, así como en modelos de regresión lineal simple.

El ejemplo clásico de distribución de Bernoulli es el lanzamiento de una moneda. Supongamos que la probabilidad de sacar cara es de 50% y de sacar cruz es igual, lo que comúnmente se asume. Sin embargo, puede darse el caso de que la moneda no sea perfecta y estas probabilidades sean distintas.

La función de masa de probabilidad para la distribución de Bernoulli se describe como:

$$
p(x) = \theta^x(1 - \theta)^{1-x}
$$

Donde $\theta$ es la probabilidad de éxito (sacar cara, por ejemplo).

En este caso, $x$ solo puede tomar valores cero o uno. Si pensamos en el ejemplo de lanzar una moneda, entonces generalmente diríamos que cero es cruz y uno es igual a cara. Theta ($\theta$) se llama parámetro y es el único parámetro de esta distribución. 

La función de masa de probabilidad para $x$ igual a uno es:

$$
p(x = 1) = \theta^1(1 - \theta)^{1-1} = \theta
$$

Y para $x$ igual a cero sería:

$$
p(x = 0) = 1 - \theta
$$

La función de verosimilitud para un conjunto de datos $data = \{x_1, x_2, x_3, ..., x_n\}$ es:

$$
L(\theta) = p(data|\theta) = \prod_{i=1}^{n} p(x_i|\theta)
$$

Y esto se puede expresar como:

$$
L(\theta) = p(data|\theta) = \prod_{i=1}^{n} \theta^{x_i} (1 - \theta)^{1-x_i}
$$

Esto no es solo una ecuación matemática, tiene significado. Esto es la probabilidad de observar los datos que observamos, suponiendo que cada lanzamiento de la moneda fuera iid (independiente e idénticamente distribuido).

Es importante comprender bien la función de verosimilitud y entender de qué realmente es una función y de qué no lo es. En realidad, aquí la variable es $\theta$ que es el valor que estamos tratando de resolver o de encontrar, porque es el parámetro de nuestra distribución.

Entonces, imagina que tenemos tres resultados del lanzamiento de la moneda, cara, cruz y cara: $x_1 = 1, x_2 = 0, x_3 = 1$

Luego los incluiríamos en la ecuación para la verosimilitud y obtendríamos lo que vemos aquí que es obviamente una función de theta, el parámetro:

$$
L(\theta) = \prod_{i=1}^{3} \theta^{x_i}(1 - \theta)^{1-x_i} = \theta^1(1 - \theta)^0\theta^1
$$

Bien, recordemos lo que estábamos haciendo. Hablamos del problema de la máxima verosimilitud y por qué se llama así. Queremos encontrar el valor de $\theta$ que hace que nuestra función de verosimilitud sea máxima, es decir, que la probabilidad de los datos observados sea la mayor posible.

Si tenemos resultados de lanzamientos de una moneda, queremos maximizar la función de verosimilitud para encontrar el valor de $\theta$.

Para ello, tomamos el logaritmo de la función de verosimilitud, que es más sencillo de maximizar debido a sus propiedades, y encontramos la derivada con respecto a $\theta$:

Log-verosimilitud:

$$
l(\theta) = \log(L(\theta)) = \log \left( \prod_{i=1}^{n} p(x_i|\theta) \right) = \sum_{i=1}^{n} \log(p(x_i|\theta))
$$

Derivamos $l(\theta)$:

$$
\frac{d}{d\theta} l(\theta) = \frac{1}{\theta} \sum_{i=1}^{n} x_i - \frac{1}{1 - \theta} \sum_{i=1}^{n} (1 - x_i)
$$

Igualamos a cero para encontrar $\theta$:

$$
\frac{1}{\theta} \sum_{i=1}^{n} x_i - \frac{1}{1 - \theta} \sum_{i=1}^{n} (1 - x_i) = 0
$$

Resolviendo para $\theta$:

$$
\theta = \frac{1}{n} \sum_{i=1}^{n} x_i
$$

Entonces, ¿tiene sentido este resultado? Claro, se alinea con lo que intuimos sobre probabilidad en experimentos aleatorios como el lanzamiento de monedas.

### Ejemplo Ratio de Clicqueo

Un área donde aplicamos conceptos similares es en el análisis de datos web, como el ratio de clicqueo (CTR). Este se asemeja a la probabilidad de obtener "cara" en nuestros experimentos aleatorios y es esencial en publicidad online y marketing digital.

El CTR se puede ver como la probabilidad de un usuario haciendo clic en un anuncio. Similarmente, la tasa de conversión se relaciona con la probabilidad de acciones deseadas, como compras o suscripciones.

Los eventos de clics y conversiones son binarios, similar a una distribución de Bernoulli. La probabilidad de éxito no es necesariamente del 50%; por ejemplo, las tasas de clics suelen ser mucho menores.

La tasa de clics (CTR) se define como:

$$
\text{CTR} = \frac{\text{número de clics}}{\text{número de impresiones}} \times 100
$$

La tasa de conversión se calcula así:

$$
\text{Tasa de Conversión} = \frac{\text{número de conversiones}}{\text{total de visitantes}} \times 100
$$

Estas tasas estiman la probabilidad de que los usuarios realicen estas acciones.

### Máxima Verosimilitud: Normal

La máxima verosimilitud también se aplica a distribuciones con más valores posibles, como la distribución normal. ¿Existe una distribución adecuada para variables continuas o reales y cómo se modela?

La distribución Normal o Gaussiana es fundamental en estadística por su versatilidad y las propiedades que posee, como el Teorema del Límite Central. Este teorema nos permite aproximar la sumatoria de variables aleatorias independientes a una distribución Normal bajo ciertas condiciones.

La aplicación de la distribución Normal se extiende más allá de la teoría, siendo útil en situaciones reales como la evaluación de resultados binarios y continuos. Por ejemplo, se utiliza para entender comportamientos de usuario en la web, como el ratio de clics o la tasa de conversión.

El proceso de estimación de máxima verosimilitud se mantiene constante, independientemente de la distribución que se esté utilizando.



# Ejemplo de Máxima Verosimilitud con Distribución Normal

Tomamos datos de altura de estudiantes, una variable continua, y aplicamos máxima verosimilitud asumiendo una distribución normal. La función de verosimilitud $L(\theta)$ para la muestra es el producto de las densidades normales individuales:

$$
L(\theta) = \prod_{i=1}^{n} f(x_i|\theta)
$$

Suponiendo normalidad, se expresa como:

$$
L(\theta) = \prod_{i=1}^{n} \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{1}{2}\left(\frac{x_i - \mu}{\sigma}\right)^2}
$$

Los parámetros $\theta$ que maximizan esta función son la media $\mu$ y la varianza $\sigma^2$ de la muestra, que caracterizan la distribución normal de las alturas.

Al aplicar el método de máxima verosimilitud a datos que siguen una distribución normal, utilizamos la función de log-verosimilitud, que para una muestra de $n$ observaciones se expresa como:

$$
l(\theta) = \sum_{i=1}^{n} \log\left(\frac{1}{\sqrt{2\pi\sigma^2}}\right) - \frac{1}{2}\left(\frac{x_i - \mu}{\sigma}\right)^2
$$

Simplificando la función de log-verosimilitud y derivando con respecto a $\mu$, obtenemos:

$$
\frac{\partial l}{\partial \mu} = \sum_{i=1}^{n} \frac{x_i - \mu}{\sigma^2}
$$

Igualando a cero la derivada y resolviendo para $\mu$:

$$
0 = \sum_{i=1}^{n} \frac{x_i - \mu}{\sigma^2}
$$



# Estimación de Máxima Verosimilitud para la Media y Varianza

La estimación de máxima verosimilitud para una distribución normal implica encontrar los valores de la media $\mu$ y la varianza $\sigma^2$. La media muestral $\hat{\mu}$ se calcula como el promedio de las observaciones y la varianza muestral $\hat{\sigma}^2$ como la media de las desviaciones al cuadrado.

La función de log-verosimilitud y su derivación con respecto a $\nu$ (una nueva variable para $\sigma^2$) se muestra a continuación:

$$
l(\nu) = -\frac{n}{2} \log(2\pi\nu) - \frac{1}{2\nu} \sum_{i=1}^{n} (x_i - \mu)^2
$$

La derivada de $l(\nu)$ con respecto a $\nu$ y la solución para $\nu$ es:

$$
0 = -\frac{n}{2\nu} + \frac{1}{2\nu^2} \sum_{i=1}^{n} (x_i - \mu)^2
$$

Resolviendo para $\nu$, obtenemos la varianza muestral:

$$
\hat{\nu} = \frac{1}{n} \sum_{i=1}^{n} (x_i - \hat{\mu})^2
$$

Esto demuestra que la varianza muestral es un estimador de máxima verosimilitud para la varianza poblacional $\sigma^2$.

# Distribución de los Estimadores

Después de hallar los estimadores de máxima verosimilitud para los parámetros de la distribución normal, exploramos sus distribuciones. Los estimadores son variables aleatorias y, por tanto, tienen sus propias distribuciones.

El estimador de la media, $\hat{\mu}$, se distribuye normalmente alrededor de la media poblacional con varianza reducida por el tamaño de la muestra:

$$
\hat{\mu} \sim Normal\left(\mu, \frac{\sigma^2}{n}\right)
$$

Con expectativa y varianza dadas por:

$$
E(\hat{\mu}) = \mu
$$

$$
Var(\hat{\mu}) = \frac{\sigma^2}{n}
$$

Para la varianza, $\hat{\sigma}^2$, el estimador es sesgado porque su expectativa no coincide con la varianza poblacional $\sigma^2$.

Sin embargo, existe un estimador no sesgado para la varianza conocido como la cuasivarianza muestral, que se define como:

$$
\hat{\sigma}^2_c = \frac{1}{n - 1} \sum_{i=1}^{n} (x_i - \hat{\mu})^2
$$

Este estimador tiene la propiedad de que su esperanza matemática es igual a la varianza poblacional:

$$
E(\hat{\sigma}^2_c) = \sigma^2
$$


# Función de Distribución

Vamos a hablar ahora de una función muy importante que caracteriza a la probabilidad asociada a una variable aleatoria. Es la función de distribución. También se llama función de distribución acumulada. En inglés Cumulative Distribution Function (CDF). Entonces, para entender la CDF, probablemente sea más intuitivo comenzar con el caso discreto, suponiendo que X es una variable aleatoria discreta. La definición es la siguiente:

$$
F(x) = P(X \leq x) = \sum_{k=-\infty}^{x} p(k)
$$

Entonces, por ejemplo, F evaluado en tres sería igual a la probabilidad de que la variable aleatoria pueda tomar un valor menor o igual a tres. Bien, entonces, ¿cómo podemos encontrar este valor? Como X en este caso es discreta:

X: variable aleatoria discreta que toma valores {0,1,2,3,...}

Supongamos que tenemos su función de masa de probabilidad PMF, que es la probabilidad de que la variable aleatoria, X pueda tomar cierto valor k minúscula:

$$
p(k) = P(X = k), \quad k = \{0,1,2,3,...\}
$$

Si queremos saber la probabilidad de que X sea menor o igual a tres, simplemente sumamos todas las probabilidades individuales, menores o iguales que 3:

$$
F(3) = P(X \leq 3) = \sum_{k=-\infty}^{3} p(k) = p(0) + p(1) + p(2) + p(3)
$$

Entonces, la probabilidad de que pueda ser tres más la probabilidad de que pueda ser dos, más la probabilidad de que pueda ser uno, más la probabilidad de que pueda ser cero y seguimos hacia abajo hasta llegar al valor más pequeño que tome nuestra variable. En este caso el valor más pequeño es cero así que paramos ahí. Al sumar todas estas probabilidades individuales, obtendremos la probabilidad total de que X sea menor o igual a tres.

Ahora, pensemos en cómo se define la CDF para el caso continuo. Como saben, cuando se trabaja con variables aleatorias continuas, las sumas se convierten en integrales:

$$
F(x) = P(X \leq x) = \int_{-\infty}^{x} f(t) \, dt
$$

Tenemos en cuenta que la t dentro de la integral se llama variable ficticia. Así que no importa qué letra usemos aquí, puede ser s, u, v, la letra que sea, mientras no sea x para no confundirnos con la otra x. No importa realmente porque al final esta variable desaparece después de tomar la integral. La CDF se halla con la integral de la PDF en el caso continuo. Y si tenemos la CDF, la PDF se puede hallar con la derivada de la CDF.