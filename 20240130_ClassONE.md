# MOTIVACIÓN DEL ENFOQUE BAYESIANO

La Estadística Bayesiana es crucial en Estadística, Ciencia de Datos y Machine Learning. Se aplica en medicina, estimando enfermedades y en marketing digital para evaluar anuncios. Este enfoque se actualiza con datos nuevos, contrario a los métodos "online" estáticos.

Se destaca en pruebas A/B, seleccionando la opción que maximiza beneficios. Por ejemplo, Facebook optimiza qué anuncios mostrar para beneficiar al usuario y al anunciante. La Estadística Bayesiana se basa en la interpretación de la probabilidad como una medida de credibilidad.

Se abordarán los fundamentos, como la definición de probabilidad y el razonamiento dentro del marco bayesiano, preparando para métodos más avanzados de inferencia bayesiana y análisis de datos.

## Conceptos Básicos

### Distribución Conjunta, Marginales y Condicionales

Vamos a suponer que tenemos dos variables aleatorias $A$ y $B$, las distribuciones marginales serían:

- $p(A)$
- $p(B)$

La distribución conjunta la denotaremos como $p(A, B)$. La coma es una forma abreviada de decir "y".

La distribución condicional, a la que nos referimos como $p(A|B)$ o $p(B|A)$.

La barra vertical es el símbolo que usamos para representar una condición. La distribución conjunta es la más general porque es a partir de esta distribución que podemos calcular todo lo demás.

Podemos calcular la distribución marginal si tenemos la distribución conjunta, de la siguiente manera:

- $p(A) = \sum_{B} p(A, B)$
- $p(B) = \sum_{A} p(A, B)$

También podemos calcular la distribución condicional usando la conjunta y la marginal:

$$
p(A|B) = \frac{p(A, B)}{p(B)} = \frac{p(A, B)}{\sum_{A} p(A, B)}
$$

$$
p(B|A) = \frac{p(A, B)}{p(A)} = \frac{p(A, B)}{\sum_{B} p(A, B)}
$$

Como sabemos que la marginal se puede calcular a partir de la conjunta, solo necesitamos la conjunta para calcular la condicional.

Podemos calcular la distribución condicional inversa si solo tenemos la condicional y la marginal. Usando la regla de las probabilidades condicionales, podemos reorganizar los términos:

$$
p(B|A) = \frac{p(A, B)}{p(A)} = \frac{p(A|B)p(B)}{\sum_{B} p(A|B)p(B)}
$$

Esto implica que podemos calcular la distribución conjunta a partir de la condicional y la marginal, lo que nos lleva al Teorema de Bayes.

Para variables continuas, las sumas se convierten en integrales:

- Densidad conjunta: $f(x, y)$
- Densidades marginales: $f(x)$, $f(y)$

$$
f(x) = \int f(x, y) \, dy
$$

$$
f(y) = \int f(x, y) \, dx
$$

Y la distribución condicional:

$$
f(x|y) = \frac{f(x, y)}{f(y)} = \frac{f(x, y)}{\int f(x, y) \, dx}
$$

$$
f(y|x) = \frac{f(x, y)}{f(x)} = \frac{f(x, y)}{\int f(x, y) \, dy}
$$

Además, la regla de Bayes también se expresa de forma análoga:

$$
f(x|y) = \frac{f(y|x)f(x)}{\int f(y|x)f(x) \, dx}
$$

$$
f(y|x) = \frac{f(x|y)f(y)}{\int f(x|y)f(y) \, dy}
$$

Simplemente reemplazamos la suma con una integral sobre la variable aleatoria relevante.

# MÁXIMA VEROSIMILITUD: DISTRIBUCIÓN DE BERNOULLI

La estimación de máxima verosimilitud es una técnica de estadística que consiste en ajustar un modelo a los datos para encontrar los mejores parámetros que modelen los datos lo más cerca posible de la realidad. Este concepto es fundamental en el aprendizaje de modelos en Machine Learning, como los modelos de clasificación y las redes neuronales en el aprendizaje profundo, así como en modelos de regresión lineal simple.

El ejemplo clásico de distribución de Bernoulli es el lanzamiento de una moneda. Supongamos que la probabilidad de sacar cara es de 50% y de sacar cruz es igual, lo que comúnmente se asume. Sin embargo, puede darse el caso de que la moneda no sea perfecta y estas probabilidades sean distintas.

La función de masa de probabilidad para la distribución de Bernoulli se describe como:

$$
p(x) = \theta^x(1 - \theta)^{1-x}
$$

Donde $\theta$ es la probabilidad de éxito (sacar cara, por ejemplo).

En este caso, \( x \) solo puede tomar valores cero o uno. Si pensamos en el ejemplo de lanzar una moneda, entonces generalmente diríamos que cero es cruz y uno es igual a cara. Theta (\( \theta \)) se llama parámetro y es el único parámetro de esta distribución. 

La función de masa de probabilidad para \( x \) igual a uno es:

$$
p(x = 1) = \theta^1(1 - \theta)^{1-1} = \theta
$$

Y para \( x \) igual a cero sería:

$$
p(x = 0) = 1 - \theta
$$

La función de verosimilitud para un conjunto de datos \( data = \{x_1, x_2, x_3, ..., x_n\} \) es:

$$
L(\theta) = p(data|\theta) = \prod_{i=1}^{n} p(x_i|\theta)
$$

Y esto se puede expresar como:

$$
L(\theta) = p(data|\theta) = \prod_{i=1}^{n} \theta^{x_i} (1 - \theta)^{1-x_i}
$$

Esto no es solo una ecuación matemática, tiene significado. Esto es la probabilidad de observar los datos que observamos, suponiendo que cada lanzamiento de la moneda fuera iid (independiente e idénticamente distribuido).

Es importante comprender bien la función de verosimilitud y entender de qué realmente es una función y de qué no lo es. En realidad, aquí la variable es \( \theta \) que es el valor que estamos tratando de resolver o de encontrar, porque es el parámetro de nuestra distribución.

Entonces, imagina que tenemos tres resultados del lanzamiento de la moneda, cara, cruz y cara:

\( x_1 = 1, x_2 = 0, x_3 = 1 \)

Luego los incluiríamos en la ecuación para la verosimilitud y obtendríamos lo que vemos aquí que es obviamente una función de theta, el parámetro:

$$
L(\theta) = \prod_{i=1}^{3} \theta^{x_i}(1 - \theta)^{1-x_i} = \theta^1(1 - \theta)^0\theta^1
$$

Bien, recordemos lo que estábamos haciendo. Hablamos del problema de la máxima verosimilitud y por qué se llama así. Queremos encontrar el valor de \( \theta \) que hace que nuestra función de verosimilitud sea máxima, es decir, que la probabilidad de los datos observados sea la mayor posible.

Si tenemos resultados de lanzamientos de una moneda, queremos maximizar la función de verosimilitud para encontrar el valor de \( \theta \).

Para ello, tomamos el logaritmo de la función de verosimilitud, que es más sencillo de maximizar debido a sus propiedades, y encontramos la derivada con respecto a \( \theta \):

Log-verosimilitud:

$$
l(\theta) = \log(L(\theta)) = \log \left( \prod_{i=1}^{n} p(x_i|\theta) \right) = \sum_{i=1}^{n} \log(p(x_i|\theta))
$$

Derivamos \( l(\theta) \):

$$
\frac{d}{d\theta} l(\theta) = \frac{1}{\theta} \sum_{i=1}^{n} x_i - \frac{1}{1 - \theta} \sum_{i=1}^{n} (1 - x_i)
$$

Igualamos a cero para encontrar \( \theta \):

$$
\frac{1}{\theta} \sum_{i=1}^{n} x_i - \frac{1}{1 - \theta} \sum_{i=1}^{n} (1 - x_i) = 0
$$

Resolviendo para \( \theta \):

$$
\theta = \frac{1}{n} \sum_{i=1}^{n} x_i
$$

Entonces, ¿tiene sentido este resultado? Claro, se alinea con lo que intuimos sobre probabilidad en experimentos aleatorios como el lanzamiento de monedas.

### Ejemplo Ratio de Clicqueo

Un área donde aplicamos conceptos similares es en el análisis de datos web, como el ratio de clicqueo (CTR). Este se asemeja a la probabilidad de obtener "cara" en nuestros experimentos aleatorios y es esencial en publicidad online y marketing digital.

El CTR se puede ver como la probabilidad de un usuario haciendo clic en un anuncio. Similarmente, la tasa de conversión se relaciona con la probabilidad de acciones deseadas, como compras o suscripciones.

Los eventos de clics y conversiones son binarios, similar a una distribución de Bernoulli. La probabilidad de éxito no es necesariamente del 50%; por ejemplo, las tasas de clics suelen ser mucho menores.

La tasa de clics (CTR) se define como:

$$
\text{CTR} = \frac{\text{número de clics}}{\text{número de impresiones}} \times 100
$$

La tasa de conversión se calcula así:

$$
\text{Tasa de Conversión} = \frac{\text{número de conversiones}}{\text{total de visitantes}} \times 100
$$

Estas tasas estiman la probabilidad de que los usuarios realicen estas acciones.

### Máxima Verosimilitud: Normal

La máxima verosimilitud también se aplica a distribuciones con más valores posibles, como la distribución normal. ¿Existe una distribución adecuada para variables continuas o reales y cómo se modela?

La distribución Normal o Gaussiana es fundamental en estadística por su versatilidad y las propiedades que posee, como el Teorema del Límite Central. Este teorema nos permite aproximar la sumatoria de variables aleatorias independientes a una distribución Normal bajo ciertas condiciones.

La aplicación de la distribución Normal se extiende más allá de la teoría, siendo útil en situaciones reales como la evaluación de resultados binarios y continuos. Por ejemplo, se utiliza para entender comportamientos de usuario en la web, como el ratio de clics o la tasa de conversión.

El proceso de estimación de máxima verosimilitud se mantiene constante, independientemente de la distribución que se esté utilizando.



# Ejemplo de Máxima Verosimilitud con Distribución Normal

Tomamos datos de altura de estudiantes, una variable continua, y aplicamos máxima verosimilitud asumiendo una distribución normal. La función de verosimilitud \( L(\theta) \) para la muestra es el producto de las densidades normales individuales:

$$
L(\theta) = \prod_{i=1}^{n} f(x_i|\theta)
$$

Suponiendo normalidad, se expresa como:

$$
L(\theta) = \prod_{i=1}^{n} \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{1}{2}\left(\frac{x_i - \mu}{\sigma}\right)^2}
$$

Los parámetros \( \theta \) que maximizan esta función son la media \( \mu \) y la varianza \( \sigma^2 \) de la muestra, que caracterizan la distribución normal de las alturas.

Al aplicar el método de máxima verosimilitud a datos que siguen una distribución normal, utilizamos la función de log-verosimilitud, que para una muestra de \( n \) observaciones se expresa como:

$$
l(\theta) = \sum_{i=1}^{n} \log\left(\frac{1}{\sqrt{2\pi\sigma^2}}\right) - \frac{1}{2}\left(\frac{x_i - \mu}{\sigma}\right)^2
$$

Simplificando la función de log-verosimilitud y derivando con respecto a \( \mu \), obtenemos:

$$
\frac{\partial l}{\partial \mu} = \sum_{i=1}^{n} \frac{x_i - \mu}{\sigma^2}
$$

Igualando a cero la derivada y resolviendo para \( \mu \):

$$
0 = \sum_{i=1}^{n} \frac{x_i - \mu}{\sigma^2}
$$



# Estimación de Máxima Verosimilitud para la Media y Varianza

La estimación de máxima verosimilitud para una distribución normal implica encontrar los valores de la media \( \mu \) y la varianza \( \sigma^2 \). La media muestral \( \hat{\mu} \) se calcula como el promedio de las observaciones y la varianza muestral \( \hat{\sigma}^2 \) como la media de las desviaciones al cuadrado.

La función de log-verosimilitud y su derivación con respecto a \( \nu \) (una nueva variable para \( \sigma^2 \)) se muestra a continuación:

$$
l(\nu) = -\frac{n}{2} \log(2\pi\nu) - \frac{1}{2\nu} \sum_{i=1}^{n} (x_i - \mu)^2
$$

La derivada de \( l(\nu) \) con respecto a \( \nu \) y la solución para \( \nu \) es:

$$
0 = -\frac{n}{2\nu} + \frac{1}{2\nu^2} \sum_{i=1}^{n} (x_i - \mu)^2
$$

Resolviendo para \( \nu \), obtenemos la varianza muestral:

$$
\hat{\nu} = \frac{1}{n} \sum_{i=1}^{n} (x_i - \hat{\mu})^2
$$

Esto demuestra que la varianza muestral es un estimador de máxima verosimilitud para la varianza poblacional \( \sigma^2 \).

