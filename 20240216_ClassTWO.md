La estadística bayesiana es una rama de la estadística en la que se utiliza el teorema de Bayes para actualizar la probabilidad de que una hipótesis sea cierta a medida que se disponga de más evidencia. Esta aproximación es especialmente útil en la inferencia estadística, donde se combina información previa (o conocimientos previos) con datos observados para hacer estimaciones o predicciones.

### Teorema de Bayes

El teorema de Bayes se puede expresar como:

$ P(H|E) = \frac{P(E|H) \cdot P(H)}{P(E)} $

Donde:
- $P(H|E)$ es la probabilidad posterior de la hipótesis $H$ dado el evento $E$.
- $P(E|H)$ es la probabilidad de observar el evento $E$ dado que la hipótesis $H$ es cierta.
- $P(H)$ es la probabilidad previa de $H$, antes de ver el evento $E$.
- $P(E)$ es la probabilidad de observar el evento $E$ bajo todas las hipótesis posibles, conocida como probabilidad marginal de $E$.

### Racional del Enfoque Bayesiano

El enfoque bayesiano se basa en la actualización de nuestras creencias en la presencia de nueva evidencia. La probabilidad previa $P(H)$ representa nuestro conocimiento o creencia antes de observar los datos. A medida que obtenemos nueva información (evidencia $E$), actualizamos esta creencia para obtener una probabilidad posterior $P(H|E)$.

La belleza del enfoque bayesiano radica en su flexibilidad para incorporar conocimientos previos y su capacidad para actualizar nuestras estimaciones a medida que se dispone de nueva información.

### Desarrollo con Ejemplos

**Ejemplo 1: Prueba de una enfermedad**

Imagina que estamos tratando de estimar la probabilidad de que una persona tenga una enfermedad basándonos en el resultado de una prueba médica.

- Supongamos que la probabilidad previa de tener la enfermedad (la prevalencia) es del 0.1% ($P(H) = 0.001$).
- La prueba tiene una tasa de verdaderos positivos (sensibilidad) del 99% ($P(E|H) = 0.99$) y una tasa de falsos positivos (1 - especificidad) del 1% ($P(E|\neg H) = 0.01$).

Queremos calcular la probabilidad de que alguien realmente tenga la enfermedad si da positivo en la prueba ($P(H|E)$).

Primero, necesitamos calcular $P(E)$, la probabilidad de dar positivo. Esto se puede hacer usando la ley total de probabilidad:

$ P(E) = P(E|H)P(H) + P(E|\neg H)P(\neg H) $

Vamos a calcularlo:

$ P(E) = 0.99 \cdot 0.001 + 0.01 \cdot 0.999 = 0.01098 $

Ahora, usando el teorema de Bayes:

$ P(H|E) = \frac{0.99 \cdot 0.001}{0.01098} \approx 0.09016 $

Esto significa que, incluso con un resultado positivo en una prueba altamente sensible, la probabilidad de que la persona realmente tenga la enfermedad es solo del aproximadamente 9.02%, debido a la baja prevalencia de la enfermedad.

**Ejemplo 2: Lanzamiento de moneda**

Supongamos que tienes una moneda y quieres estimar la probabilidad de que caiga cara ($H$). Antes de lanzar la moneda, tu creencia previa es que hay un 50% de probabilidad de que caiga cara ($P(H) = 0.5$).

Si lanzas la moneda 10 veces y observas 7 caras ($E$), puedes actualizar tu creencia sobre la probabilidad de que la moneda caiga cara usando el teorema de Bayes.

La actualización precisa en este caso implicaría calcular la verosimilitud de observar los datos dado el modelo, lo cual requiere un modelo estadístico más complejo para la distribución de los datos (como la distribución binomial en este caso). Sin embargo, el proceso conceptual sigue siendo el mismo: ajustas tu creencia previa basándote en la evidencia observada para obtener una nueva probabilidad posterior.

Estos ejemplos ilustran cómo el teorema de Bayes permite incorporar evidencia nueva a nuestras creencias previas de una manera coherente y matemáticamente rigurosa, proporcionando una herramienta poderosa para la inferencia estadística.

Vamos a explorar dos ejemplos adicionales aplicando el teorema de Bayes con un desarrollo detallado y formulación explícita para ilustrar cómo se utiliza en situaciones prácticas.

### Ejemplo 3: Filtro de spam en un correo electrónico

Supongamos que estamos desarrollando un filtro de spam para un servicio de correo electrónico y queremos calcular la probabilidad de que un correo electrónico sea spam basándonos en la presencia de cierta palabra clave, por ejemplo, "ganador".

- **Probabilidad previa** ($P(\text{Spam}))$: Es la probabilidad de que cualquier correo electrónico sea spam antes de considerar la presencia de la palabra "ganador". Supongamos que es del 20% ($0.2$).

- **Probabilidad de evidencia dada la hipótesis** ($P(\text{"ganador"}|\text{Spam}))$: Es la probabilidad de encontrar la palabra "ganador" en un correo electrónico dado que es spam. Supongamos que es del 50% ($0.5$).

- **Probabilidad de evidencia** ($P(\text{"ganador"}))$: Es la probabilidad de encontrar la palabra "ganador" en cualquier correo electrónico. Para calcularla, necesitamos saber también la probabilidad de encontrar "ganador" en un correo no spam ($P(\text{"ganador"}|\neg\text{Spam}))$, supongamos que es del 1% ($0.01$).

Primero, calculamos $P(\text{"ganador"})$, la probabilidad total de ver la palabra "ganador":

$ P(\text{"ganador"}) = P(\text{"ganador"}|\text{Spam})P(\text{Spam}) + P(\text{"ganador"}|\neg\text{Spam})P(\neg\text{Spam}) $

$ = 0.5 \cdot 0.2 + 0.01 \cdot 0.8 = 0.1 + 0.008 = 0.108 $

Ahora aplicamos el teorema de Bayes para calcular la probabilidad posterior de que un correo electrónico sea spam dado que contiene la palabra "ganador":

$ P(\text{Spam}|\text{"ganador"}) = \frac{P(\text{"ganador"}|\text{Spam}) \cdot P(\text{Spam})}{P(\text{"ganador"})} $

$ = \frac{0.5 \cdot 0.2}{0.108} \approx 0.926 $

Este resultado indica que, si un correo electrónico contiene la palabra "ganador", la probabilidad de que sea spam aumenta significativamente a aproximadamente 92.6%.

### Ejemplo 4: Determinar la fiabilidad de un testigo

En un caso judicial, un testigo afirma haber visto a un coche azul en la escena del crimen. Queremos calcular la probabilidad de que el coche en la escena del crimen fuera realmente azul basándonos en la fiabilidad del testigo.

- **Probabilidad previa** ($P(\text{Azul}))$: La probabilidad previa de que un coche en la escena del crimen fuera azul, basada en estadísticas de color de coche, es del 15% ($0.15$).

- **Probabilidad de evidencia dada la hipótesis** ($P(\text{Testigo ve azul}|\text{Azul}))$: La probabilidad de que el testigo diga que el coche es azul si realmente lo era, es decir, la fiabilidad del testigo, es del 80% ($0.8$).

- **Probabilidad de evidencia** ($P(\text{Testigo ve azul}))$: Es necesario calcular la probabilidad total de que el testigo diga "azul", que incluye la posibilidad de que el testigo esté equivocado al identificar coches de otros colores como azules. Supongamos que la probabilidad de que el testigo diga "azul" cuando no lo es (falsos positivos) es del 10% ($0.1$).

Calculamos $P(\text{Testigo ve azul})$:

$ P(\text{Testigo ve azul}) = P(\text{Testigo ve azul}|\text{Azul})P(\text{Azul}) + P(\text{Testigo ve azul}|\neg\text{Azul})P(\neg\text{Azul}) $

$ = 0

.8 \cdot 0.15 + 0.1 \cdot 0.85 = 0.12 + 0.085 = 0.205 $

Utilizamos el teorema de Bayes para calcular la probabilidad posterior de que el coche fuera azul dado que el testigo lo vio azul:

$ P(\text{Azul}|\text{Testigo ve azul}) = \frac{P(\text{Testigo ve azul}|\text{Azul}) \cdot P(\text{Azul})}{P(\text{Testigo ve azul})} $

$ = \frac{0.8 \cdot 0.15}{0.205} \approx 0.585 $

Este resultado indica que, dado el testimonio del testigo, la probabilidad de que el coche en la escena del crimen fuera azul es de aproximadamente 58.5%, lo que refleja una mejora significativa en la confianza respecto a la probabilidad previa del 15% basada únicamente en la fiabilidad del testigo y las estadísticas generales de color de coche.

Estos ejemplos demuestran cómo el teorema de Bayes permite integrar evidencia específica dentro de un marco probabilístico para actualizar nuestras creencias o conocimientos previos de manera cuantitativa.